# Hands On ML- Part 1, Ch.8 - Dimensionality Reduction
These are notes, code and exercise solutions for chapter 8 from "Hands On Machine Learning" (2nd Edition) by Aurélien Géron
<br>
Check it out: https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1492032646

<h3>Subject covered in this chapter:</h3>

<h3>Section: The Curse of Dimensionality</h3>

<h3>Section: Main Approaches for Dimensionality Reduction</h3>
<blockquote>Projection</blockquote>
<blockquote>Manifold Learning</blockquote>

<h3>Section: Technique #1 PCA (Projection approach)</h3>
<blockquote>Preserving the Variance</blockquote>
<blockquote>Principal Components</blockquote>
<blockquote>Projecting Down to d Dimensions</blockquote>
<blockquote>Explained Variance Ratio</blockquote>
<blockquote>Choosing the Right Number of Dimensions</blockquote>
<blockquote>PCA for Compression</blockquote>
<blockquote>Randomized PCA</blockquote>
<blockquote>Incremental PCA</blockquote>
<blockquote>Time complexity</blockquote>

<h3>Section: Technique #2 Kernell PCA (Projection approach)</h3>
<blockquote>Selecting a Kernel and Tuning Hyperparameters</blockquote>

<h3>Section: Technique #3 LLE (Manifold Learning approach)</h3>

<h3>Section: Other Dimensionality Reduction Techniques</h3>

<h3>Section: Solutions To The Exercise Questions</h3>

